# Oral X-Ray Demo Platform

## English

### Overview

This branch contains a streamlined proof-of-concept for the cross-attention dental X-ray demo. Only the FastAPI service that powers the `/demo` endpoints and the accompanying Next.js page remain. All legacy dashboard pages, authentication flows, and auxiliary training utilities have been removed to keep the repository focused on the interactive demo experience.

### Repository Layout

```
teeth_project/
â”œâ”€â”€ demo_backend/           # FastAPI service that powers /demo/samples and /demo/infer
â”‚   â”œâ”€â”€ _vendor/            # Bundled inference utilities (cross-attention + YOLO helpers)
â”‚   â”œâ”€â”€ main.py             # FastAPI entrypoint for the demo API
â”‚   â”œâ”€â”€ pipeline.py         # Cross-attention inference pipeline
â”‚   â”œâ”€â”€ samples.py          # Static sample metadata loader
â”‚   â””â”€â”€ requirements.txt    # Python dependencies for demo_backend
â”œâ”€â”€ frontend/               # Next.js 14 App Router project
â”‚   â”œâ”€â”€ app/demo/page.tsx   # Single remaining UI route
â”‚   â””â”€â”€ lib/                # Minimal API client, types, and media helpers
â”œâ”€â”€ models/                 # YOLO detector and classifier checkpoints used by the demo
â””â”€â”€ README.md               # This file (English & Chinese instructions)
```

### Prerequisites

- Python 3.10 or newer with `pip`
- Node.js 18 or newer with `npm` or `yarn`
- (Optional) CUDA-capable GPU for faster inference; CPU mode works but is slower

### Quick Start

1. **Prepare a Python environment**  
   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate  # macOS/Linux: source .venv/bin/activate
   pip install -r demo_backend/requirements.txt
   ```

2. **Launch the FastAPI demo service**  
   ```bash
   uvicorn demo_backend.main:app --reload
   ```
   The API exposes:
   - `GET /demo/samples` â€“ list of bundled sample radiographs
   - `POST /demo/infer` â€“ run cross-attention inference on an uploaded image or sample ID
   - `GET /demo-outputs/*` â€“ static files generated by the pipeline

3. **Run the Next.js frontend** (in a new terminal)  
   ```bash
   cd frontend
   npm install
   npm run dev
   ```
   Visit `http://localhost:3000/demo` to access the UI. The page automatically targets the local FastAPI service. If you host the API elsewhere, export `NEXT_PUBLIC_API_BASE_URL` before running `npm run dev`.

### Backend Configuration

Environment variables can be used to customize the runtime without editing code:

| Variable | Description | Default |
| --- | --- | --- |
| `DEMO_YOLO_WEIGHTS` | Path to the YOLO detector checkpoint | `models/fdi_all seg.pt` |
| `DEMO_CLASSIFIER_WEIGHTS` | Path to the cross-attention classifier weights | `models/cross_attn_fdi_camAlignA.pth` |
| `DEMO_LAYERED_THRESHOLDS` | Optional JSON thresholds file | *(unset)* |
| `DEMO_OUTPUT_DIR` | Directory for inference outputs | `demo_backend/outputs` |
| `DEMO_STATIC_DIR` | Directory that hosts static samples | `demo_backend/static` |
| `DEMO_DEVICE` | `cuda` or `cpu` device preference | `cuda` |
| `DEMO_AUTOLOAD` | Autoload models at startup (`true` / `false`) | `false` |

Sample assets live in `demo_backend/static/samples/`. Add more JPG/PNG files to surface them automatically in the modal selector.

### Frontend Notes

- `frontend/lib/api.ts` provides the only client helpers (`fetchDemoSamples`, `submitDemoInference`).
- `frontend/lib/types.ts` contains the shared demo response contracts.
- Tailwind CSS classes are scoped to the demo page; unused layouts and components have been pruned.

### Typical Demo Flow

1. Start the backend (`uvicorn demo_backend.main:app --reload`).
2. Open `http://localhost:3000/demo` and pick a predefined sample or upload a custom radiograph.
3. Toggle Grad-CAM overlays, zoom/pan the panoramic view, and inspect per-tooth predictions.
4. Download the generated overlay image or CSV from the backend-served output links.

---

## ä¸­æ–‡

### æ¦‚è¿°

æ­¤åˆ†æ”¯åƒ…ä¿ç•™äº¤å‰æ³¨æ„åŠ›ç‰™ç§‘ X å…‰ Demo æ‰€éœ€çš„æœ€å°åŒ–ç¨‹å¼ç¢¼ã€‚åŸå…ˆçš„å„€è¡¨æ¿ã€å¸³è™Ÿç³»çµ±èˆ‡è¨“ç·´è…³æœ¬å‡å·²ç§»é™¤ï¼Œåªå‰©ä¸‹ FastAPI Demo æœå‹™èˆ‡ Next.js `/demo` å–®ä¸€è·¯ç”±ï¼Œæ–¹ä¾¿å±•ç¤ºæ¨è«–æµç¨‹èˆ‡ Grad-CAM ç–Šå±¤çµæœã€‚

### å°ˆæ¡ˆçµæ§‹

```
teeth_project/
â”œâ”€â”€ demo_backend/           # FastAPI Demo æœå‹™ï¼ˆæä¾› /demo/samples åŠ /demo/inferï¼‰
â”‚   â”œâ”€â”€ _vendor/            # å…§å»ºä¹‹æ¨è«–å·¥å…·ï¼ˆYOLO + Cross-Attentionï¼‰
â”‚   â”œâ”€â”€ main.py             # Demo API é€²å…¥é»
â”‚   â”œâ”€â”€ pipeline.py         # äº¤å‰æ³¨æ„åŠ›æ¨è«–æµç¨‹
â”‚   â”œâ”€â”€ samples.py          # ç¯„ä¾‹å½±åƒèˆ‡æè¿°
â”‚   â””â”€â”€ requirements.txt    # Demo å¾Œç«¯æ‰€éœ€å¥—ä»¶
â”œâ”€â”€ frontend/               # Next.js 14ï¼ˆApp Routerï¼‰å‰ç«¯
â”‚   â”œâ”€â”€ app/demo/page.tsx   # å”¯ä¸€å‰©ä¸‹çš„é é¢
â”‚   â””â”€â”€ lib/                # Demo å°ˆç”¨ API å·¥å…·èˆ‡å‹åˆ¥
â”œâ”€â”€ models/                 # Demo ä½¿ç”¨çš„ YOLO èˆ‡åˆ†é¡å™¨æ¬Šé‡
â””â”€â”€ README.md               # æ­¤æ–‡ä»¶ï¼ˆå«ä¸­è‹±æ–‡èªªæ˜ï¼‰
```

### ç’°å¢ƒéœ€æ±‚

- Python 3.10 ä»¥ä¸Šï¼ˆå»ºè­°æ­é…è™›æ“¬ç’°å¢ƒï¼‰
- Node.js 18 ä»¥ä¸Šï¼ˆå« npm æˆ– yarnï¼‰
- ï¼ˆé¸ç”¨ï¼‰æ”¯æ´ CUDA çš„ GPUï¼Œå¯ç¸®çŸ­æ¨è«–æ™‚é–“ï¼›è‹¥ç„¡å‰‡è‡ªå‹•ä½¿ç”¨ CPU

### å¿«é€Ÿå•Ÿå‹•

1. **å»ºç«‹ Python ç’°å¢ƒä¸¦å®‰è£å¥—ä»¶**  
   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate  # macOS/Linux: source .venv/bin/activate
   pip install -r demo_backend/requirements.txt
   ```

2. **å•Ÿå‹• FastAPI Demo æœå‹™**  
   ```bash
   uvicorn demo_backend.main:app --reload
   ```
   ä¸»è¦ç«¯é»å¦‚ä¸‹ï¼š
   - `GET /demo/samples`ï¼šå–å¾—å…§å»ºç¤ºç¯„å½±åƒæ¸…å–®
   - `POST /demo/infer`ï¼šä¸Šå‚³å½±åƒæˆ–æŒ‡å®š `sample_id` è§¸ç™¼æ¨è«–
   - `GET /demo-outputs/*`ï¼šè®€å–æ¨è«–è¼¸å‡ºçš„ç–Šåœ–èˆ‡ CSV

3. **å•Ÿå‹•å‰ç«¯**ï¼ˆå¦é–‹çµ‚ç«¯æ©Ÿï¼‰  
   ```bash
   cd frontend
   npm install
   npm run dev
   ```
   ç€è¦½ `http://localhost:3000/demo` å³å¯ä½¿ç”¨ä»‹é¢ã€‚è‹¥å¾Œç«¯éƒ¨ç½²æ–¼å…¶ä»–ä½ç½®ï¼Œè«‹åœ¨ `npm run dev` å‰è¨­å®š `NEXT_PUBLIC_API_BASE_URL`ã€‚

### å¾Œç«¯ç’°å¢ƒè®Šæ•¸

| è®Šæ•¸ | èªªæ˜ | é è¨­å€¼ |
| --- | --- | --- |
| `DEMO_YOLO_WEIGHTS` | YOLO åˆ†å‰²æ¨¡å‹æ¬Šé‡è·¯å¾‘ | `models/fdi_all seg.pt` |
| `DEMO_CLASSIFIER_WEIGHTS` | äº¤å‰æ³¨æ„åŠ›åˆ†é¡å™¨æ¬Šé‡ | `models/cross_attn_fdi_camAlignA.pth` |
| `DEMO_LAYERED_THRESHOLDS` | ï¼ˆé¸ç”¨ï¼‰å¤šå±¤é–€æª»è¨­å®š JSON | *(æœªè¨­å®š)* |
| `DEMO_OUTPUT_DIR` | æ¨è«–è¼¸å‡ºè³‡æ–™å¤¾ | `demo_backend/outputs` |
| `DEMO_STATIC_DIR` | éœæ…‹è³‡ç”¢æ ¹ç›®éŒ„ | `demo_backend/static` |
| `DEMO_DEVICE` | æ¨è«–è£ç½®ï¼ˆ`cuda` æˆ– `cpu`ï¼‰ | `cuda` |
| `DEMO_AUTOLOAD` | å•Ÿå‹•æ™‚æ˜¯å¦é å…ˆè¼‰å…¥æ¨¡å‹ (`true`/`false`) | `false` |

ç¤ºç¯„å½±åƒæ”¾åœ¨ `demo_backend/static/samples/`ã€‚æ–°å¢ JPG/PNG æª”å³å¯è‡ªå‹•å‡ºç¾åœ¨å‰ç«¯é¸å–®å…§ã€‚

### å‰ç«¯èªªæ˜

- `frontend/lib/api.ts` åƒ…ä¿ç•™ `fetchDemoSamples` èˆ‡ `submitDemoInference` å…©é …å‘¼å«ã€‚
- `frontend/lib/types.ts` å®šç¾©æ¨è«–çµæœèˆ‡ç‰™é½’æª¢æ¸¬çš„å‹åˆ¥ã€‚
- Tailwind æ¨£å¼åƒ…ä½œç”¨æ–¼ `/demo`ï¼Œå…¶ä»–ç‰ˆé¢èˆ‡å…ƒä»¶çš†å·²ç§»é™¤ã€‚

### ç¤ºç¯„æµç¨‹

1. åŸ·è¡Œ `uvicorn demo_backend.main:app --reload` å•Ÿå‹•å¾Œç«¯ã€‚
2. æ‰“é–‹ `http://localhost:3000/demo`ï¼Œé¸æ“‡å…§å»ºæ¨£æœ¬æˆ–è‡ªè¡Œä¸Šå‚³å½±åƒã€‚
3. ç€è¦½æ¨è«–çµæœã€å•Ÿç”¨ Grad-CAM ç–Šå±¤ã€æ”¾å¤§/ç¸®å°å½±åƒä¸¦æŸ¥è©¢ç‰¹å®š FDI ç‰™ä½ã€‚
4. é€éä»‹é¢ä¸Šçš„é€£çµä¸‹è¼‰ç–Šå±¤å½±åƒæˆ– CSV çµæœæª”æ¡ˆã€‚

Enjoy exploring the cross-attention dental X-ray demo! / ç¥æ‚¨å±•ç¤ºé †åˆ© ğŸ‰
